{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Script for Running a Sweep with WandB logging\n",
    "\n",
    "<p> Wandb (Weights and Biases) is a service that evaluates and saves model parameters while providing excellent visualisation tools - ideal for running experiments. Here, you'll see how you can use wandb in tandem with the GNM toolbox </p>\n",
    "\n",
    "<p><i>Wandb is a seperate service not affiliated with this toolbox - for wandb-specific support, have a look at their documentation.</i></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports from the package with torch and numpy\n",
    "import numpy as np\n",
    "import torch\n",
    "from gnm.fitting.experiment_saving import *\n",
    "from gnm.fitting.experiment_dataclasses import Experiment\n",
    "from gnm import defaults, fitting, generative_rules, weight_criteria, evaluation\n",
    "\n",
    "# import wandb - run 'pip install wandb' if it's not already installed\n",
    "import wandb\n",
    "\n",
    "# Use the correct Device - this is CPU or GPU (use GPU if you have one to utilize parallelization\n",
    "# which will speed things up considerably)\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# load the basic matrices - here, we'll just use a binary network\n",
    "distance_matrix = defaults.get_distance_matrix(device=DEVICE)\n",
    "binary_consensus_network = defaults.get_binary_network(device=DEVICE)\n",
    "\n",
    "# login using wandb - you'll need to create an account if you\n",
    "# dont have one already \n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the basic parameters - we'll iterate through just 4 combinations \n",
    "# here for demonstration purposes, but you can set this to any number\n",
    "\n",
    "eta_values = torch.Tensor([1, 1.5]) #torch.linspace(-5, -1, 1)\n",
    "gamma_values = torch.Tensor([-1, -0.5])#torch.linspace(-0.5, 0.5, 1)\n",
    "num_connections = int( binary_consensus_network.sum().item() / 2 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the basic and for the most part, default parameters you'd use in a run. \n",
    "# Have a look at the other example scripts for an in-depth look at the parameters and how you can \n",
    "# use them yourself.\n",
    "\n",
    "# The binary sweep parameters are the parameters that are used to generate the binary network\n",
    "binary_sweep_parameters = fitting.BinarySweepParameters(\n",
    "    eta = eta_values,\n",
    "    gamma = gamma_values,\n",
    "    lambdah = torch.Tensor([0.0]),\n",
    "    distance_relationship_type = [\"powerlaw\"],\n",
    "    preferential_relationship_type = [\"powerlaw\"],\n",
    "    heterochronicity_relationship_type = [\"powerlaw\"],\n",
    "    generative_rule = [generative_rules.MatchingIndex()],\n",
    "    num_iterations = [num_connections],\n",
    ")\n",
    "\n",
    "# The weighted sweep parameters are the parameters that are used to generate the weighted network\n",
    "weighted_sweep_parameters = fitting.WeightedSweepParameters(\n",
    "    alpha = [0.01],\n",
    "    optimisation_criterion = [weight_criteria.DistanceWeightedCommunicability(distance_matrix=distance_matrix) ],\n",
    ")  \n",
    "\n",
    "\n",
    "# The sweep config is the object that contains all the parameters for the sweep\n",
    "# and is used to generate the networks.\n",
    "sweep_config = fitting.SweepConfig(\n",
    "    binary_sweep_parameters = binary_sweep_parameters,\n",
    "    weighted_sweep_parameters = weighted_sweep_parameters,\n",
    "    num_simulations = 1,\n",
    "    distance_matrix = [distance_matrix]    \n",
    ")\n",
    "\n",
    "# additonal cirteria to evaluate the generative model against a real connectome\n",
    "criteria = [ evaluation.ClusteringKS(), evaluation.DegreeKS(), evaluation.EdgeLengthKS(distance_matrix) ]\n",
    "energy = evaluation.MaxCriteria( criteria )\n",
    "binary_evaluations = [energy]\n",
    "weighted_evaluations = [ evaluation.WeightedNodeStrengthKS(normalise=True), evaluation.WeightedClusteringKS() ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Run the experment sweep. You should see a wandb link in the terminal. Follow this\n",
    "# link to see the model parameters visualized in the wandb dashboard. This will make \n",
    "# parameter combinations easier to visualize and understand.\n",
    "experiments = fitting.perform_sweep(sweep_config=sweep_config, \n",
    "                                binary_evaluations=binary_evaluations, \n",
    "                                real_binary_matrices=binary_consensus_network,\n",
    "                                weighted_evaluations=weighted_evaluations,\n",
    "                                save_model = False,\n",
    "                                save_run_history = False,\n",
    "                                verbose=True,\n",
    "                                wandb_logging=True # Set this to true for logging, it's False by default\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
