{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gnm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgnm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgnm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m defaults, utils, evaluation, fitting, generative_rules, weight_criteria\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gnm'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "notebook_dir = os.getcwd() \n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join(notebook_dir, '..', 'src')))\n",
    "\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from gnm import *\n",
    "from gnm import defaults, utils, evaluation, fitting, generative_rules, weight_criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing sweeps\n",
    "\n",
    "In this example notebook, we use the gnm package to perform a sweep over generative rules and parameter values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in data\n",
    "\n",
    "We'll start by loading in some data for our sweep. In particular, we'll need:\n",
    "1. A distance matrix\n",
    "2. A binary network to compare our networks to\n",
    "\n",
    "We'll get these from the defaults sub-module, which has a built in distance matrix and consensus network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix = defaults.get_distance_matrix(device=DEVICE)\n",
    "binary_consensus_network = defaults.get_binary_network(device=DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll run the models until they have the same number of connections as the real binary consensus network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The binary consensus network contains 400 connections.\n"
     ]
    }
   ],
   "source": [
    "num_connections = int( binary_consensus_network.sum().item() / 2 )\n",
    "print(f\"The binary consensus network contains {num_connections} connections.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining our sweep\n",
    "\n",
    "The next step is to define the parameters we want to sweep over. Here, we'll sweep over a range of values for $\\eta$ and $\\gamma$, while keeping the generative rule fixed (using the Matching Index) and the weight optimisation criterion fixed (using the distance weighted communicability).   \n",
    "\n",
    "For each set of parameters, we'll generate 100 networks using the model with that set of parameters. This means setting the number of simulations to 100. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta_values = torch.linspace(-5, -1, 9)\n",
    "gamma_values = torch.linspace(-0.5, 0.5, 11)\n",
    "\n",
    "binary_sweep_parameters = fitting.BinarySweepParameters(\n",
    "    eta = eta_values,\n",
    "    gamma = gamma_values,\n",
    "    lambdah = torch.Tensor([0.0]),\n",
    "    distance_relationship_type = [\"powerlaw\"],\n",
    "    preferential_relationship_type = [\"powerlaw\"],\n",
    "    heterochronicity_relationship_type = [\"powerlaw\"],\n",
    "    generative_rule = [generative_rules.MatchingIndex()],\n",
    "    num_iterations = [num_connections],\n",
    ")\n",
    "\n",
    "weighted_sweep_parameters = fitting.WeightedSweepParameters(\n",
    "    alpha = [0.01],\n",
    "    optimisation_criterion = [weight_criteria.DistanceWeightedCommunicability(distance_matrix=distance_matrix) ],\n",
    ")   \n",
    "\n",
    "num_simulations = 100\n",
    "\n",
    "sweep_config = fitting.SweepConfig(\n",
    "    binary_sweep_parameters = binary_sweep_parameters,\n",
    "    weighted_sweep_parameters = weighted_sweep_parameters,\n",
    "    num_simulations = num_simulations,\n",
    "    distance_matrices = [distance_matrix],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating our evaluations\n",
    "\n",
    "We want to evaluate how good the fit of our models is the real binary consensus network.\n",
    "For our evaluation criteria, we'll use the maximum of the KS statistics across clustering coefficient, degree, and edge length distributions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria = [ evaluation.ClusteringKS(), evaluation.DegreeKS(), evaluation.EdgeLengthKS(distance_matrix) ]\n",
    "energy = evaluation.MaxCriteria( criteria )\n",
    "binary_evaluations = [energy]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to evaluate the fit of the weighted networks. We'll give a couple of evaluations for the weighted networks as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_evaluations = [ evaluation.WeightedNodeStrengthKS(distance_matrix), evaluation.WeightedClusteringKS() ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing the sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "experiments = fitting.perform_sweep(sweep_config=sweep_config, \n",
    "                                binary_evaluations=binary_evaluations, \n",
    "                                real_binary_matrices=binary_consensus_network,\n",
    "                                weighted_evaluations=weighted_evaluations,\n",
    "                                save_only_evaluations=True,\n",
    ")\n",
    "\n",
    "end_time = time.perf_counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the efficiency of the sweep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sweep took 532.486 seconds.\n",
      "Total number of simulations: 9900\n",
      "Average time per simulation: 0.054 seconds.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Sweep took {end_time - start_time:0.3f} seconds.\")\n",
    "\n",
    "total_simulations = num_simulations * len(eta_values) * len(gamma_values)\n",
    "\n",
    "print(f\"Total number of simulations: {total_simulations}\")\n",
    "\n",
    "print(f\"Average time per simulation: {(end_time - start_time) / total_simulations:0.3f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_experiments, optimal_energies = fitting.optimise_evaluation(\n",
    "    experiments=experiments,\n",
    "    criterion=energy,\n",
    ")\n",
    "\n",
    "optimal_experiment = optimal_experiments[0]\n",
    "optimal_energy = optimal_energies[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal energy: 0.182\n",
      "Optimal value of eta: -2.00\n",
      "Optimal value of gamma: 0.30\n"
     ]
    }
   ],
   "source": [
    "print(f\"Optimal energy: {optimal_energy:0.3f}\")\n",
    "print(f\"Optimal value of eta: {optimal_experiment.run_config.binary_parameters.eta:0.2f}\")\n",
    "print(f\"Optimal value of gamma: {optimal_experiment.run_config.binary_parameters.gamma:0.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
