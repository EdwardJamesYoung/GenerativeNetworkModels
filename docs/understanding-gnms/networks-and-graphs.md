# Networks and Graphs

## What is a Network?

A network is a way of representing a complex system which can be decomposed into distinct sub-units, for which we can calculate some metric of association between those sub-units. A brain, international travel systems, and telecommunications infrastructure can all be thought of as, and modelled, as networks. The term `graph' is often used interchangeably with network. Indeed, Graph Theory provides us with a mathematical language for describing and characterising networks. In the language of Graph Theory the network is made up of nodes – the sub-units – and the association between those nodes are termed edges. This framework can be used to describe many different real-world systems. For example, The Web. The Web can be described as a network, with nodes representing webpages and the edges between those nodes representing hyperlinks between the webpages. In other networks, edges will represent physical connections - for example, a graph in which the nodes represent train stations, and edges represent direct train lines between those stations. Graphs can also be used to describe abstract relationships; for example, each of our nodes could represent a chess board, with edges between nodes if there is a legal move by either player which takes us from one board to another.

By describing a system as a network, we can capture the pattern of connectivity between elements while abstracting away the details of both how the system is implemented and the identity or properties of individual nodes beyond the connections they make. When we describe The Web as a network, and each webpage as a node, we are abstracting away from all the other details about each webpage - for example, the colour scheme it uses, what text it contains, and whether it contains any images or videos. Similarly, in describing the train system in a country as a network, we're abstracting away from details such as the physical distance between connected stops and the population of nearby cities.   

## Brains as Networks

In order to represent the brain as a network, it must be divided into distinct regions which can serve as [nodes](glossary.md#node). This division is called a [parcellation](glossary.md#parcellation). There are several types of parcellations commonly used in network neuroscience. Cortical parcellations divide the cortical surface into regions based on anatomical landmarks or functional properties, whilst volumetric parcellations partition the entire brain volume including subcortical structures. Cytoarchitectural parcellations rely on differences in cellular organisation and structure between brain regions, whilst connectivity parcellations group regions based on similar patterns of connections with other brain areas. Common parcellation schemes include the Automated Anatomical Labelling (AAL) atlas, which provides a standardised parcellation based on anatomical landmarks, and the Schaefer parcellation, which uses functional connectivity to define cortical regions at multiple scales.

Once the brain has been parcellated into areas represented by [nodes](glossary.md#nodes), we must determine the pattern of [edges](glossary.md#edge) between those nodes, representing connectivity between brain regions. [Structural connectivity](glossary.md#structural-connectivity) refers to the physical connections between areas formed by white matter tracts. [Structural connectivity](glossary.md#structural-connectivity) can be measured using techniques such as diffusion tensor imaging (DTI) and tractography, where we use the diffusion properties brain tissues to infer the presence and strength of physical connections between areas. In contrast, [functional connectivity](glossary.md#functional-connectivity) captures statistical relationships between the activities of different brain regions, for example, through the correlation in measured neural activity. The most common way of doing this is to use blood deoxygenation as a down-stream proxy for neural activity, measured using Functional Magnetic Resonance Imaging (fMRI). There are many other good examples, like using multi-electrode arrays to assay network organisation at a micro scale, but these are the most common. In principle, Generative Network Models can be used to model the formation of edges within any network, but hte most common applications are to [structural connectivity](glossary.md#structural-connectivity). 

<!-- 
[You could put something in here about how the subsequent examples and datasets you use will be structural connectivity… just to give a little context for why you are then focussing on this]. -->

To determine [structural connectivity](glossary.md#structural-connectivity), it is typical to use diffusion MRI (magnetic resonance imaging). Diffusion MRI can be used measure the diffusion of water molecules throughout the brain. Tractography algorithms can then reconstruct the paths that white matter tracts make through the brain on the basis of this diffusion data. For example, streamline count gives the number of reconstructed fibre bundles connecting pairs of regions.

Reconstructions of [structural connectivity](glossary.md#structural-connectivity) data are typically then post-processed. Data can be combined across multiple subjects or scanning sessions to create robust group-level connectivity estimates called a consensus network. Thresholding removes weak connections that may represent noise, using either absolute thresholds (removing connections below a fixed strength) or relative thresholds (keeping only the consistent connections across participants). By default, the connecivity thereby obtained will be [weighted](glossary.md#weight-matrix), meaning that strenghts are assigned to each edge in accordance with the estimated size of the white matter tract between those regions. Binarisation can convert this into a [unweighted](glossary.md#adjacency-matrix) network by ignoring strength estimates, and setting all remaining connections to have a value of $1$, and all absent connections a value of $0$. 

![Figure 1](figures-png/fig1.png)

## Representing Networks

A useful representation of an unweighted network is via its [adjacency matrix](glossary.md#adjacency-matrix-a), denoted $A$. When two nodes have an edge between them, we say they are [adjacent](glossary.md#adjacent). [Adjacency matrices](glossary.md#adjacency-matrix) captures which nodes are adjacent as follows: if [nodes](glossary.md#node) $i$ and $j$ are connected by an [edge](glossary.md#edge), we set $A_{ij} = A_{ji} = 1$. Conversely, when no such edge exists we set $A_{ij} = A_{ji} = 0$. The [adjacency matrix](glossary.md#adjacency-matrix) is therefore [binary](glossary.md#binary-generative-network-model), in the sense that it contains only $0$s and $1$s, as well as [symmetric](glossary.md#symmetric), meaning $A_{ij} = A_{ji}$. 

The [adjacency matrix](glossary.md#adjacency-matrix-a) representation has several useful mathematical properties. The [degree](glossary.md#degree) of a [node](glossary.md#node) is the total number of edges that node is at the end of. To compute the degree of $s_i$ of node $i$, we can sum over each node $j$ within the network, and add a $1$ if $j$ is adjacent to $i$ or a zero if not. The degree is therefore $s_i = \sum_j A_{ij}$. Likewise, powers of the [adjacency matrix](glossary.md#adjacency-matrix-a) give  connectivity information beyond direct connections (adjacency). For example, take two nodes $i$ and $j$. A [path](glossary.md#path) between $i$ and $j$ is a sequence of nodes which starts with $i$ and ends with $j$ such that each pair of nodes is adjacent. Accordingly, $i$ and $j$ are adjacent if there is a path of length $1$ between them, $i,j$. So $A_{ij}$ captures the presence of paths of length $1$. Paths are a useful way of quantifying *indirect* connectivity between nodes, with paths of increasing length as less preferable communication pathways. The number of paths of length $2$ between $i$ and $j$ is equal to the number of nodes $k$ in the network such that $i$ is adjacent to $k$ and $k$ is adjacent to $j$. So to compute the number of such paths, we simply sum over nodes $k$ in the network, and add $1$ if both $A_{ik}$ and $A_{kj}$. This is simply $\sum_k A_{ik} A_{kj} = [A^2]_{ij}$, where we have used the definition of matrix multiplication. A similar argument reveals that higher powers continue this patter; $[A^n]_{ij}$ gives the number of paths between $i$ and $j$ which have length $n$. As a special case of this, $(1/2) [A^3]_{ii}$ counts the number of triangles which $i$ is involved in (the factor of $(1/2)$ accounts for the fact that $i,j,k,i$ and $i,k,j,i$ are the same triangle). 

When the edges within a network have weights, we can instead use a [weight matrix](glossary.md#weight-matrix-w), denoted $W$. This generalises the [adjacency matrix](glossary.md#adjacency-matrix-a) by allowing $W_{ij}$ to take any non-negative value representing the strength of the connection between [nodes](glossary.md#node) $i$ and $j$. Like the [adjacency matrix](glossary.md#adjacency-matrix-a), the [weight matrix](glossary.md#weight-matrix-w) is typically [symmetric](glossary.md#symmetric). When $W_{ij} = 0$, no connection exists between the [nodes](glossary.md#node); when $W_{ij} > 0$, the magnitude indicates the strength of the connection. The [weight matrix](glossary.md#weight-matrix-w) preserves all the structural information of the [adjacency matrix](glossary.md#adjacency-matrix-a) while providing additional detail about connection strengths. Many network measures can be adapted from binary to weighted versions by incorporating these connection strengths into the calculations. 

## Network Measures

Often, when we are comparing two large datasets, we may find it easiest to first compare the mean and variance of these datasets rather than looking at each item individually. This is because the mean and variance are useful *summary statistics*, which tell us about what a dataset looks like while abstracting away from each of the individual samples within that dataset. Similarly, when comparing two networks, we may find it useful to summarise important information about the networks which give us a high-level view of how the network behaves while avoiding enumerating every connection within the network.  Network measures are a way of doing this - they provide a way of summarising and encapsulating the properties of a node or network. Below, we give a selection of network measures at both the level of individual nodes and at the level of the whole network. May other measures exist which are not listed here; instead, we focus on a subset of measures that are used within the Generative Network Model. 

### Node-Level Measures

One property of a node we might be interested in is its overall connectivity - does it form many connections to other nodes or few? In a binary network, the [degree](glossary.md#degree) of a [node](glossary.md#node) is the most basic measure of its connectivity, counting the total number of [edges](glossary.md#edge) attached to that [node](glossary.md#node). The degree of node $i$ can be computed by summing over all other nodes $j$, and adding $1$ if they are connected. In terms of the adjacency matrix $A$, the degree of $i$ is thus given by $s_i = \sum_j A_{ij}$. In brain networks, [degree](glossary.md#degree) indicates how many other regions a particular brain area connects to directly. High-[degree](glossary.md#degree) [nodes](glossary.md#node) often serve as hubs in the network, facilitating communication between many different regions. For weighted networks, node degree is generalised to [node strength](glossary.md#node-strength), which is the sum of the weights of all edges attached to a node. It can be computed analogously as $s_i = \sum_j W_{ij}$. 

The [clustering coefficient](glossary.md#clustering-coefficient) of a [node](glossary.md#node) measures the extent to which it is at the centre of a local cluster of nodes. The clustering coefficient is larger when the [neighbours](glossary.md#neighbour) of a node are also connected to one another. Specifically, the clustering coefficient is the proportion of possible [edges](glossary.md#edge) between a [node's](glossary.md#node) [neighbours](glossary.md#neighbour) that are actually present. For [node](glossary.md#node) $i$, the clustering coefficient is equal to the number of connections between $i$'s neighbours divided by the number of pairs of neighbours. The number of connections between $i$'s neighbours is simply the number of triangles in which $i$ is a vertex, since if two of $i$'s neighbours $j, k$ are connected then $i, j, k$ are all connected and therefore form a triangle. The possible number of connections between $i$'s neighbours is the same as the number of *pairs* of $i$'s neighbours. To find the number of pairs of $i$'s neighbours, we first count the number of neighbours $j$ of $i$ (which is equal to the degree of $i$, $s_i$), and then multiply by the number of neighbours $k$ of $i$ which are not $j$ (which will be $s_i - 1$). We then divide by $2$ to account for the fact that this counts the pair $j,k$ twice (as $j,k$ and $k,j$). Thus, the number of neighbours is $s_i(s_i - 1)/2$. Putting this together, the clustering coefficient is
$$
c_i = \frac{ (A^3)\_{ii}/2 }{ s_i(s_i -1)/2 } = \frac{ (A^3)\_{ii} }{s_i(s_i - 1)}.
$$
High [clustering](glossary.md#clustering-coefficient) indicates that a [node's](glossary.md#node) [neighbours](glossary.md#neighbour) form a tightly interconnected local community.

[Betweenness centrality](glossary.md#betweenness-centrality) of a [node](glossary.md#node) $i$ measures how vital that node is for information flow through the network. Specifically, betweenness centrality is a measure of how often $i$ sits on the [shortest paths](glossary.md#shortest-path) between other [nodes](glossary.md#node) in the [network](glossary.md#network). A [shortest path](glossary.md#shortest-path) between nodes is a [path](glossary.md#path) which contains the least number of edges of any path connecting those nodes. For each pair of other [nodes](glossary.md#node) $j,k \neq i$ in the [network](glossary.md#network), we identify all [shortest paths](glossary.md#shortest-path) connecting them. We then compute the faction of these shortest paths which pass through $i$. We then sum (or average) this fraction across all pairs of other nodes within the network to compute the [betweenness centrality](glossary.md#betweenness-centrality). This measure identifies [nodes](glossary.md#node) that serve as important bridges or bottlenecks for information flow, even if they do not have particularly high [degree](glossary.md#degree).

These three measures - degree, clustering coefficient, and betweenness centrality - summarise properties of a node - overall connectivity, local integration, and importance for information flow, respectivley. As noted at the outset, there are other measures not discussed here we could use to quantify these properties (or completely different properties of a node). We have chosen to focus specifically on those that are used within the toolbox. 

### Network-Level Measures

Network-level measures serve as summary statistics that characterise the properties of an entire [network](glossary.md#network). These measures provide a way to quantify and compare different aspects of network organisation while abstracting from the lower-level details of the exact connectivity pattern. Here, we give four network-level statistics - global clustering coefficient, network density, characteristic path length, and small worldness. Again, many other measures exist which summarise other properties of the network. 

The global [clustering coefficient](glossary.md#clustering-coefficient) of a [network](glossary.md#network) is computed as the average [clustering coefficient](glossary.md#clustering-coefficient) across all [nodes](glossary.md#node). This measure indicates the overall tendency for [nodes](glossary.md#node) in the [network](glossary.md#network) to form locally clustered communities. High global [clustering](glossary.md#clustering-coefficient) suggests a [network](glossary.md#network) organisation that supports local processing and segregated function.

Network density $\rho$ measures the proportion of possible [edges](glossary.md#edge) that are actually present in the [network](glossary.md#network). This is equal to the number of edges in the network dvided by the number of pairs of nodes in the network. If there are $N$ nodes and $E$ edges, then (by a similar argument to the above) this is
$$
\rho = \frac{\text{Number of edges}}{\text{Number of pairs of nodes}} = \frac{E}{N(N-1)/2} = \frac{2E}{N(N-1)}.
$$ 
Density provides a simple measure of how extensively connected a [network](glossary.md#network) is, with values ranging from 0 (no connections) to 1 (completely connected).

The [characteristic path length](glossary.md#characteristic-path-length), $\ell$ represents the average [shortest path](glossary.md#shortest-path) length across all pairs of [nodes](glossary.md#node) in the [network](glossary.md#network). This provides a measure of the typical number of steps required to travel between any two [nodes](glossary.md#node), quantifying tthe global efficiency of the [network](glossary.md#network) for information transmission. Lower [characteristic path length](glossary.md#characteristic-path-length) indicates more efficient global connectivity.

We say a network has the small world property if it has high global clustering - indicating that nodes tend to form localised sub-communities - while having a low characteristic path length - indicating that it is typically easy to get from any node to any other node. Whether the gloabl clustering coefficient and characteristic path length of a graph are high is quantified by comparing to a set of  random graphs which have the same density. Specifically, we generate a large number of random graphs which have the same density, and compute the average clustering coefficient and characteristic path length of those graphs, $C_{\rm random}$ and $\ell_{\rm random}$ respectively. We then compare the the actual gloabl clustering coefficient $C$ and characteristic path length $\ell$ of the graph to the randomised quantities, $C / C_{\rm random}$ and $\ell / \ell_{\rm random}$. We compare these to compute the small worldness, 
$$
 \text{small worldess} = \frac{C / C_{\rm random}}{ \ell / \ell_{\rm random}}
$$