{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "notebook_dir = os.getcwd() \n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join(notebook_dir, '..', 'src')))\n",
    "\n",
    "import torch\n",
    "from gnm import *\n",
    "from gnm import defaults, utils, evaluation, fitting, generative_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing sweeps\n",
    "\n",
    "In this example notebook, we use the gnm package to perform a sweep over generative rules and parameter values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in data\n",
    "\n",
    "We'll start by loading in some data for our sweep. In particular, we'll need:\n",
    "1. A distance matrix\n",
    "2. A binary network to compare our networks to\n",
    "\n",
    "We'll get these from the defaults sub-module, which has a built in distance matrix and consensus network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix = defaults.get_distance_matrix(device=torch.device('cpu'))\n",
    "binary_consensus_network = defaults.get_binary_network(device=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll run the models until they have the same number of connections as the real binary consensus network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The binary consensus network contains 400 connections.\n"
     ]
    }
   ],
   "source": [
    "num_connections = int( binary_consensus_network.sum().item() / 2 )\n",
    "print(f\"The binary consensus network contains {num_connections} connections.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining our sweep\n",
    "\n",
    "The next step is to define the parameters we want to sweep over. Here, we'll examine a range of values for $\\eta$ and $\\gamma$, for the two homophily-based wiring rules, the Matching Index rule. \n",
    "\n",
    "For each set of parameters, we'll generate 100 networks using the model with that set of parameters. This means setting the number of simulations to 100. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_sweep_parameters = fitting.BinarySweepParameters(\n",
    "    eta = torch.linspace(-1, 1, 6),\n",
    "    gamma = torch.linspace(-1, 1, 6),\n",
    "    lambdah = torch.Tensor([0.0]),\n",
    "    distance_relationship_type = [\"powerlaw\"],\n",
    "    preferential_relationship_type = [\"powerlaw\"],\n",
    "    heterochronicity_relationship_type = [\"powerlaw\"],\n",
    "    generative_rule = [generative_rules.MatchingIndex()],\n",
    "    num_iterations = [num_connections],\n",
    ")\n",
    "\n",
    "num_simulations = 100\n",
    "\n",
    "sweep_config = fitting.SweepConfig(\n",
    "    binary_sweep_parameters = binary_sweep_parameters,\n",
    "    num_simulations = num_simulations,\n",
    "    distance_matrices = [distance_matrix],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating our evaluations\n",
    "\n",
    "We want to evaluate how good the fit of our models is the real binary consensus network. We'll use the standard evaluation criterion, which is the maximum of the KS statistics across the betweenness centrality, clustering coefficient, degree, and edge length distributions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria = [ evaluation.BetweennessKS(), evaluation.ClusteringKS(), evaluation.DegreeKS(), evaluation.EdgeLengthKS(distance_matrix) ]\n",
    "energy = evaluation.MaxCriteria( criteria )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing the sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = fitting.perform_sweep(sweep_config=sweep_config, \n",
    "                                binary_evaluations=[energy], \n",
    "                                real_binary_matrices=binary_consensus_network,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing the results\n",
    "\n",
    "We can now analyse the sweep. \n",
    "The sweep outputs a list of Experiment dataclasses, which have two fields: run_config and results. \n",
    "We'll go through the sweep and find the energy for each parameter combination. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_best_config = results[0].run_config\n",
    "current_best_energy = results[0].results.binary_evaluations['Maximum(Binary betweenness centrality KS, Binary clustering coefficient KS, Binary degree KS, Binary edge length KS)'].mean()\n",
    "\n",
    "for experiment in results:\n",
    "    energies = experiment.results.binary_evaluations['Maximum(Binary betweenness centrality KS, Binary clustering coefficient KS, Binary degree KS, Binary edge length KS)']\n",
    "    if energies.mean() < current_best_energy:\n",
    "        current_best_config = experiment.run_config\n",
    "        current_best_energy = energies.mean() \n",
    "\n",
    "plt.imshow()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
